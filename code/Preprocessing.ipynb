{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Conversion C3D en JSON rééchantilloné à 50 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ezc3d\n",
    "import json\n",
    "from scipy.signal import resample,butter, lfilter, freqz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperer_evenements(file_path):\n",
    "    \"\"\"\n",
    "    Cette fonction extrait les événements du fichier C3D.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Le chemin du fichier C3D.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant les événements et leur temps correspondant.\n",
    "    \"\"\"\n",
    "    c3d = ezc3d.c3d(file_path)\n",
    "    events = c3d['parameters']['EVENT']['LABELS']['value'] # Récupérer les événements\n",
    "    frames = c3d['parameters']['EVENT']['TIMES']['value'] # Récupérer les temps correspondant aux événements\n",
    "    events_dict = {}\n",
    "    for event, frame in zip(events, frames): # Associer les événements à leur temps correspondant\n",
    "        events_dict[event] = frame \n",
    "    return events_dict\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    \"\"\"\n",
    "    Crée les coefficients d'un filtre Butterworth passe-bas.\n",
    "\n",
    "    Args:\n",
    "        cutoff (float): Fréquence de coupure du filtre.\n",
    "        fs (float): Fréquence d'échantillonnage du signal.\n",
    "        order (int): Ordre du filtre.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Coefficients du filtre (b, a).\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs # Fréquence de Nyquist\n",
    "    normal_cutoff = cutoff / nyq # Fréquence de coupure normalisée\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False) # Création des coefficients du filtre\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    \"\"\"\n",
    "    Applique un filtre Butterworth passe-bas à un signal.\n",
    "\n",
    "    Args:\n",
    "        data (array_like): Signal à filtrer.\n",
    "        cutoff (float): Fréquence de coupure du filtre.\n",
    "        fs (float): Fréquence d'échantillonnage du signal.\n",
    "        order (int): Ordre du filtre.\n",
    "\n",
    "    Returns:\n",
    "        array_like: Signal filtré.\n",
    "    \"\"\"\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def reechantillonnage_fc_coupure_et_association_labels_et_data(file_path, cutoff_freq=20, target_freq=50):\n",
    "    \"\"\"\n",
    "    Cette fonction transforme les données échantillonnées à 2100 Hz en données échantillonnées à 50 Hz,\n",
    "    puis applique un filtre Butterworth passe-bas avec une fréquence de coupure de 20 Hz, et enfin associe les étiquettes des données aux données rééchantillonnées et filtrées.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Le chemin du fichier C3D.\n",
    "        cutoff_freq (float): Fréquence de coupure du filtre Butterworth (20 Hz).\n",
    "        target_freq (float): Fréquence cible après rééchantillonnage (50 Hz).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Un tuple contenant un dictionnaire fusionnant les étiquettes et les données rééchantillonnées et filtrées, et les temps rééchantillonnés.\n",
    "    \"\"\"\n",
    "    c3d = ezc3d.c3d(file_path)\n",
    "    labels = c3d['parameters']['ANALOG']['LABELS']['value'] # Récupérer les étiquettes des données\n",
    "    original_freq = c3d['parameters']['ANALOG']['RATE']['value'][0] # Récupérer la fréquence d'échantillonnage\n",
    "    data = c3d['data']['analogs'] # Récupérer les données\n",
    "    nb_frame = len(data[0][0]) # Récupérer le nombre de frames\n",
    "    target_freq = 50  # fréquence de rééchantillonnage\n",
    "    \n",
    "    # Rééchantillonnage des données\n",
    "    nb_samples_target = int(nb_frame * (target_freq / original_freq)) # Calcul du nombre d'échantillons cible\n",
    "    resampled_times = np.linspace(0., (nb_frame / original_freq), num=nb_samples_target) # Création d'un tableau de temps rééchantillonné\n",
    "    resampled_data = np.zeros((len(labels), nb_samples_target)) # Création d'un tableau de zéros de la taille des données rééchantillonnées\n",
    "    for i in range(len(labels)): # Pour chaque étiquette\n",
    "        resampled_data[i, :] = resample(data[0][i, :], nb_samples_target) # Rééchantillonnage des données\n",
    "\n",
    "    fusion_label_data = {}\n",
    "    for i, label in enumerate(labels): # Pour chaque étiquette\n",
    "        fusion_label_data[label] = resampled_data[i, :] # Associer les étiquettes aux données rééchantillonnées\n",
    "        \n",
    "    # Filtrage des données rééchantillonnées\n",
    "    filtered_data = np.zeros_like(resampled_data) # Création d'un tableau de zéros de la même taille que les données rééchantillonnées\n",
    "    for i in range(len(labels)): # Pour chaque étiquette\n",
    "        filtered_data[i, :] = butter_lowpass_filter(resampled_data[i, :], cutoff_freq, target_freq) # Appliquer un filtre passe-bas\n",
    "\n",
    "    fusion_label_data = {}\n",
    "    for i, label in enumerate(labels): \n",
    "        fusion_label_data[label] = filtered_data[i, :] # Associer les étiquettes aux données filtrées\n",
    "    \n",
    "    return fusion_label_data, resampled_times\n",
    "    \n",
    "\n",
    "def filtrer_labels(fusion_label_data):\n",
    "    \"\"\"\n",
    "    Cette fonction filtre les étiquettes des données pour ne garder que celles liées à l'accéléromètre et au gyroscope.\n",
    "\n",
    "    Args:\n",
    "        fusion_label_data (dict): Dictionnaire contenant les étiquettes et les données associées.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Un tuple contenant une liste des étiquettes filtrées et un dictionnaire des données associées aux étiquettes filtrées.\n",
    "    \"\"\"\n",
    "    labels_filtre = []\n",
    "    labels_data_filtre = {}\n",
    "    for label, valeurs in fusion_label_data.items(): # Pour chaque étiquette et ses valeurs\n",
    "        if 'ACC' in label or 'GYRO' in label: # Si l'étiquette contient 'ACC' ou 'GYRO'\n",
    "            labels_filtre.append(label) # Ajouter l'étiquette à la liste des étiquettes filtrées\n",
    "            labels_data_filtre[label] = valeurs # Ajouter les valeurs associées à l'étiquette dans le dictionnaire des données filtrées\n",
    "    return labels_filtre, labels_data_filtre\n",
    "\n",
    "def calcul_norme(labels_data_filtre):\n",
    "    \"\"\"\n",
    "    Cette fonction calcule les normes des données filtrées.\n",
    "\n",
    "    Args:\n",
    "        labels_data_filtre (dict): Dictionnaire contenant les étiquettes et les données associées, filtrées.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dictionnaire contenant les normes calculées.\n",
    "    \"\"\"\n",
    "    normes = {}\n",
    "    traite = set() # Créer un ensemble vide pour stocker les capteurs, les côtés et les mesures déjà traités\n",
    "    for key, value in labels_data_filtre.items():\n",
    "        parts = key.split('_') # Séparer l'étiquette en parties\n",
    "        sensor = parts[0] # Récupérer le capteur\n",
    "        side = parts[1] # Récupérer le côté\n",
    "        measure = parts[2] # Récupérer la mesure (GYRO ou ACC)\n",
    "        \n",
    "        if (sensor, side, measure) not in traite: # Si le capteur, le côté et la mesure n'ont pas déjà été traités\n",
    "            traite.add((sensor, side, measure)) # Ajouter le capteur, le côté et la mesure à l'ensemble des éléments traités\n",
    "            \n",
    "            if \"ACC\" in measure:\n",
    "                # Obtention des axes X, Y et Z\n",
    "                axe_X = labels_data_filtre[f'{sensor}_{side}_{measure}_X']\n",
    "                axe_Y = labels_data_filtre[f'{sensor}_{side}_{measure}_Y']\n",
    "                axe_Z = labels_data_filtre[f'{sensor}_{side}_{measure}_Z']\n",
    "            \n",
    "                norme = np.sqrt(axe_X**2 + axe_Y**2 + axe_Z**2) - 1 # Calcul de la norme auquelle on soustrait 1 pour enlever la gravité\n",
    "                nom_cle = f'{sensor}_{side}_{measure}_norme'\n",
    "                normes[nom_cle] = norme\n",
    "                \n",
    "            else:\n",
    "                axe_X = labels_data_filtre[f'{sensor}_{side}_{measure}_X']\n",
    "                axe_Y = labels_data_filtre[f'{sensor}_{side}_{measure}_Y']\n",
    "                axe_Z = labels_data_filtre[f'{sensor}_{side}_{measure}_Z']\n",
    "        \n",
    "                norme = np.sqrt(axe_X**2 + axe_Y**2 + axe_Z**2) \n",
    "                nom_cle = f'{sensor}_{side}_{measure}_norme'\n",
    "                normes[nom_cle] = norme\n",
    "\n",
    "    return normes\n",
    "\n",
    "def creer_structure_json(labels_data_filtre, patient_id, date_de_naissance, medicaments, resampled_times, events_dict, normes):\n",
    "    \"\"\"\n",
    "    Cette fonction crée une structure JSON à partir des données filtrées et d'autres informations.\n",
    "\n",
    "    Args:\n",
    "        labels_data_filtre (dict): Dictionnaire contenant les étiquettes et les données associées, filtrées.\n",
    "        patient_id (int): Identifiant du patient.\n",
    "        date_de_naissance (str): Date de naissance du patient.\n",
    "        medicaments (str): Médicaments pris par le patient.\n",
    "        resampled_times (ndarray): Temps rééchantillonné.\n",
    "        events_dict (dict): Dictionnaire contenant les événements et leur temps correspondant.\n",
    "        normes (dict): Dictionnaire contenant les normes calculées.\n",
    "\n",
    "    Returns:\n",
    "        dict: Structure JSON contenant les données et les métadonnées.\n",
    "    \"\"\"\n",
    "    json_data = {\n",
    "        \"metadata\": {\n",
    "            \"Détails du patient\": {\n",
    "                \"Identifiant\": patient_id,\n",
    "                \"Date de naissance\": date_de_naissance,\n",
    "                \"Medicaments\": medicaments\n",
    "            },\n",
    "            \"Temps\": resampled_times.tolist()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for key, value in labels_data_filtre.items():\n",
    "        parts = key.split('_')\n",
    "        sensor = parts[1]\n",
    "        side = parts[0]\n",
    "        measure = parts[2]\n",
    "        axis = parts[3]\n",
    "        \n",
    "        if sensor not in json_data:\n",
    "            json_data[sensor] = {}\n",
    "\n",
    "        if side not in json_data[sensor]:\n",
    "            json_data[sensor][side] = {}\n",
    "\n",
    "        if measure not in json_data[sensor][side]:\n",
    "            json_data[sensor][side][measure] = {}\n",
    "\n",
    "        json_data[sensor][side][measure][axis] = value.tolist()\n",
    "        \n",
    "    for key in normes:\n",
    "        parts = key.split('_')\n",
    "        sensor = parts[1]\n",
    "        side = parts[0]\n",
    "        measure = parts[2]\n",
    "        axis = parts[3]\n",
    "\n",
    "        if sensor not in json_data:\n",
    "            json_data[sensor] = {}\n",
    "\n",
    "        if side not in json_data[sensor]:\n",
    "            json_data[sensor][side] = {}\n",
    "\n",
    "        if measure not in json_data[sensor][side]:\n",
    "            json_data[sensor][side][measure] = {}\n",
    "\n",
    "        # Insérer la norme au même niveau d'indentation que l'axe\n",
    "        json_data[sensor][side][measure][axis] = value.tolist()\n",
    "        json_data[sensor][side][measure][\"norme\"] = normes[key].tolist()\n",
    "    \n",
    "    # Ajouter les événements FOG\n",
    "    json_data[\"FOG\"] = {\n",
    "        \"Debut\": events_dict[\"FOG_begin\"].tolist(),\n",
    "        \"Fin\": events_dict[\"FOG_end\"].tolist()\n",
    "    }\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "def creation_json_grace_c3d(file_path, patient_id, date_de_naissance, medicaments, output_path):\n",
    "    \"\"\"\n",
    "    Cette fonction crée un fichier JSON à partir d'un fichier C3D.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Le chemin du fichier C3D.\n",
    "        patient_id (int): Identifiant du patient.\n",
    "        date_de_naissance (str): Date de naissance du patient.\n",
    "        medicaments (str): Médicaments pris par le patient.\n",
    "        output_path (str): Le chemin de sortie du fichier JSON.\n",
    "    \"\"\"\n",
    "    events_dict = recuperer_evenements(file_path) \n",
    "    fusion_label_data, resampled_times = reechantillonnage_fc_coupure_et_association_labels_et_data(file_path)\n",
    "    labels_filtre, labels_data_filtre = filtrer_labels(fusion_label_data)\n",
    "    normes = calcul_norme(labels_data_filtre)\n",
    "    json_structure = creer_structure_json(labels_data_filtre, patient_id, date_de_naissance, medicaments, resampled_times, events_dict, normes)\n",
    "    \n",
    "    with open(output_path, \"w\") as fichier_json:\n",
    "        json.dump(json_structure, fichier_json, indent=4)\n",
    "\n",
    "# Utilisation de la fonction pour traiter le fichier C3D et générer le fichier JSON\n",
    "fichier_brut = \"C:/Users/antho/Documents/MEMOIRE_M2/CODE_STAGE_M2/DATA_FOG/LE_LIEVRE_Emmanuel_1971_03_19_LEEM1971/2023-05-26/2023-05-26_overlay_detectFOG/Video_overlay_3.c3d\"\n",
    "patient_id = 1234\n",
    "date_de_naissance = 45\n",
    "medicaments = \"ON\"\n",
    "chemin_sortie = \"C:/Users/antho/Documents/MEMOIRE_M2/CODE_STAGE_M2/DATABASE/video_overlay_3.json\"\n",
    "\n",
    "creation_json_grace_c3d(fichier_brut, patient_id, date_de_naissance, medicaments, chemin_sortie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier JSON\n",
    "chemin_fichier_json = \"C:/Users/antho/Documents/MEMOIRE_M2/CODE_STAGE_M2/DATABASE/video_overlay_3.json\"\n",
    "with open(chemin_fichier_json, \"r\") as fichier_json:\n",
    "    donnees_patient = json.load(fichier_json)\n",
    "\n",
    "# Accéder aux données spécifiques\n",
    "#temps = donnees_patient[\"Rectus Femoris\"][\"Left\"][\"ACC\"][\"norme\"]\n",
    "temps = donnees_patient[\"metadata\"][\"Temps\"]\n",
    "gyro_x= donnees_patient[\"Rectus Femoris\"][\"Left\"][\"GYRO\"][\"X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion C3D en JSON sans rééchantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperer_evenements(file_path):\n",
    "    c3d = ezc3d.c3d(file_path)\n",
    "    events = c3d['parameters']['EVENT']['LABELS']['value']\n",
    "    frames = c3d['parameters']['EVENT']['TIMES']['value']\n",
    "    events_dict = {}\n",
    "    for event, frame in zip(events, frames):\n",
    "        events_dict[event] = frame\n",
    "    return events_dict\n",
    "\n",
    "def associer_labels_et_data(file_path):\n",
    "    c3d = ezc3d.c3d(file_path)\n",
    "    labels = c3d['parameters']['ANALOG']['LABELS']['value']\n",
    "    frequence = c3d['parameters']['ANALOG']['RATE']['value'][0]\n",
    "    data = c3d['data']['analogs']\n",
    "    nb_frame = len(data[0][0])\n",
    "    temps = np.linspace(0., nb_frame / frequence, num=nb_frame)\n",
    "    fusion_label_data = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        fusion_label_data[label] = data[0][i, :]\n",
    "    return fusion_label_data, temps   # Dictionnaire avec tous les labels associés aux données\n",
    "\n",
    "def filtrer_labels(fusion_label_data):\n",
    "    labels_filtre = []\n",
    "    labels_data_filtre = {}\n",
    "    for label, valeurs in fusion_label_data.items():\n",
    "        if 'ACC' in label or 'GYRO' in label:\n",
    "            labels_filtre.append(label)\n",
    "            labels_data_filtre[label] = valeurs\n",
    "    return labels_filtre, labels_data_filtre # Dictionnaire avec les labels filtrés et les données associées\n",
    "\n",
    "def calcul_norme(labels_data_filtre):\n",
    "    normes = {}\n",
    "    traite = set()\n",
    "    for key, value in labels_data_filtre.items():\n",
    "        parts = key.split('_')\n",
    "        sensor = parts[0]\n",
    "        side = parts[1]\n",
    "        measure = parts[2]\n",
    "        axes = parts[3]\n",
    "        \n",
    "        if (sensor, side, measure) not in traite:\n",
    "            traite.add((sensor, side, measure))\n",
    "            \n",
    "            if \"ACC\" in measure:\n",
    "                # Obtention des axes X, Y et Z\n",
    "                axe_X = labels_data_filtre[f'{sensor}_{side}_{measure}_X']\n",
    "                axe_Y = labels_data_filtre[f'{sensor}_{side}_{measure}_Y']\n",
    "                axe_Z = labels_data_filtre[f'{sensor}_{side}_{measure}_Z']\n",
    "            \n",
    "                norme = np.sqrt(axe_X**2 + axe_Y**2 + axe_Z**2) - 1\n",
    "                nom_cle = f'{sensor}_{side}_{measure}_norme'\n",
    "                normes[nom_cle] = norme\n",
    "                \n",
    "            else :\n",
    "                axe_X = labels_data_filtre[f'{sensor}_{side}_{measure}_X']\n",
    "                axe_Y = labels_data_filtre[f'{sensor}_{side}_{measure}_Y']\n",
    "                axe_Z = labels_data_filtre[f'{sensor}_{side}_{measure}_Z']\n",
    "        \n",
    "                norme = np.sqrt(axe_X**2 + axe_Y**2 + axe_Z**2)\n",
    "                nom_cle = f'{sensor}_{side}_{measure}_norme'\n",
    "                normes[nom_cle] = norme\n",
    "\n",
    "    return normes\n",
    "\n",
    "def creer_structure_json(labels_data_filtre, patient_id, date_de_naissance, medicaments, temps, events_dict, normes):\n",
    "    json_data = {\n",
    "        \"metadata\": {\n",
    "            \"Détails du patient\": {\n",
    "                \"Identifiant\": patient_id,\n",
    "                \"Date de naissance\": date_de_naissance,\n",
    "                \"Medicaments\": medicaments\n",
    "            },\n",
    "            \"Temps\": temps.tolist()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for key, value in labels_data_filtre.items():\n",
    "        parts = key.split('_')\n",
    "        sensor = parts[1]\n",
    "        side = parts[0]\n",
    "        measure = parts[2]\n",
    "        axis = parts[3]\n",
    "        \n",
    "        if sensor not in json_data:\n",
    "            json_data[sensor] = {}\n",
    "\n",
    "        if side not in json_data[sensor]:\n",
    "            json_data[sensor][side] = {}\n",
    "\n",
    "        if measure not in json_data[sensor][side]:\n",
    "            json_data[sensor][side][measure] = {}\n",
    "\n",
    "        json_data[sensor][side][measure][axis] = value.tolist()\n",
    "        \n",
    "    for key in normes:\n",
    "        parts = key.split('_')\n",
    "        sensor = parts[1]\n",
    "        side = parts[0]\n",
    "        measure = parts[2]\n",
    "        axis = parts[3]\n",
    "\n",
    "        if sensor not in json_data:\n",
    "            json_data[sensor] = {}\n",
    "\n",
    "        if side not in json_data[sensor]:\n",
    "            json_data[sensor][side] = {}\n",
    "\n",
    "        if measure not in json_data[sensor][side]:\n",
    "            json_data[sensor][side][measure] = {}\n",
    "\n",
    "        # Insérer la norme au même niveau d'indentation que l'axe\n",
    "        json_data[sensor][side][measure][axis] = value.tolist()\n",
    "        json_data[sensor][side][measure][\"norme\"] = normes[key].tolist()\n",
    "    \n",
    "        # Ajouter les événements FOG\n",
    "    json_data[\"FOG\"] = {\n",
    "        \"Debut\": events_dict[\"FOG_begin\"].tolist(),\n",
    "        \"Fin\": events_dict[\"FOG_end\"].tolist()\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return json_data\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def creation_json_grace_c3d(file_path, patient_id, date_de_naissance, medicaments, output_path):\n",
    "    events_dict = recuperer_evenements(file_path) \n",
    "    fusion_label_data, temps = associer_labels_et_data(file_path)\n",
    "    labels_filtre, labels_data_filtre = filtrer_labels(fusion_label_data)\n",
    "    normes = calcul_norme(labels_data_filtre)\n",
    "    json_structure = creer_structure_json(labels_data_filtre, patient_id, date_de_naissance, medicaments, temps, events_dict, normes)\n",
    "    \n",
    "    with open(output_path, \"w\") as fichier_json:\n",
    "        json.dump(json_structure, fichier_json, indent=4)\n",
    "\n",
    "# Utilisation de la fonction pour traiter le fichier C3D et générer le fichier JSON\n",
    "fichier_brut = \"C:/Users/antho/Documents/MEMOIRE_M2/CODE_STAGE_M2/DATA_FOG/LE_LIEVRE_Emmanuel_1971_03_19_LEEM1971/2023-05-26/2023-05-26_overlay_detectFOG/Video_overlay_3.c3d\"\n",
    "patient_id = 1234\n",
    "date_de_naissance = 45\n",
    "medicaments = \"ON\"\n",
    "chemin_sortie = \"C:/Users/antho/Documents/MEMOIRE_M2/CODE_STAGE_M2/DATABASE/video_overlay_3.json\"\n",
    "\n",
    "creation_json_grace_c3d(fichier_brut, patient_id, date_de_naissance, medicaments, chemin_sortie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier JSON\n",
    "chemin_fichier_json = \"C:/Users/antho/Documents/MEMOIRE_M2/CODE_STAGE_M2/DATABASE/video_overlay_3.json\"\n",
    "with open(chemin_fichier_json, \"r\") as fichier_json:\n",
    "    donnees_patient = json.load(fichier_json)\n",
    "\n",
    "# Accéder aux données spécifiques\n",
    "accelerometre_left_Z_rectus_femoris = donnees_patient[\"Vastus Lateralis\"][\"Left\"][\"GYRO\"][\"norme\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
