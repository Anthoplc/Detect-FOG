{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from main import PreProcessing, Statistics\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import mode, median_abs_deviation, iqr, trim_mean, entropy as ent, skew, kurtosis\n",
    "from scipy.signal import welch, correlate, stft\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.fft import fft, fftfreq\n",
    "import entropy as ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/antho/Documents/MEMOIRE_M2/c3d_audeline/A_P_1956-02-21_ON_DM_1.c3d\"\n",
    "# file_path = \"C:/Users/antho/Documents/MEMOIRE_M2/CODE_STAGE_M2/DATA_FOG/LE_LIEVRE_Emmanuel_1971_03_19_LEEM1971/2023-05-26/2023-05-26_overlay_detectFOG/Video overlay 15.c3d\"\n",
    "# Définir les informations du patient\n",
    "# Instancier l'objet DetectFog\n",
    "detector = PreProcessing(file_path)\n",
    "detector.creation_json_grace_c3d()\n",
    "detector.extract_data_interval()\n",
    "detector.normalize_data() \n",
    "detector.decoupage_en_fenetres()\n",
    "detector.label_fenetre()\n",
    "detector.association_label_fenetre_data()\n",
    "data = detector.concat_label_fenetre_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données Temporelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enlever_derniere_ligne_et_colonne_label_frequence(data):\n",
    "#     for sensor, sensor_data in data.items():\n",
    "#         if sensor not in [\"metadata\", \"parcours\", \"FOG\"]:\n",
    "#             for side, side_data in sensor_data.items():\n",
    "#                 for measure, measure_data in side_data.items():\n",
    "#                     for axis, axis_data in measure_data.items():\n",
    "#                         if isinstance(axis_data, pd.DataFrame):\n",
    "                        \n",
    "#                             # Supprimer la dernière ligne du DataFrame\n",
    "#                             data_moins_derniere_ligne_na = axis_data.drop(axis_data.index[-1])\n",
    "#                             # print(data_moins_derniere_ligne_na)\n",
    "#                             label = data_moins_derniere_ligne_na[\"label\"]\n",
    "                        \n",
    "#                             # Vérifier si la colonne 'label' existe avant de la supprimer\n",
    "#                             if 'label' in data_moins_derniere_ligne_na.columns:\n",
    "#                                 data_moins_colonne_label = data_moins_derniere_ligne_na.drop(columns=[\"label\"])\n",
    "#                                 # Mise à jour du DataFrame dans le dictionnaire\n",
    "#                                 measure_data[axis] = data_moins_colonne_label\n",
    "                                                            \n",
    "#     return data,label\n",
    "\n",
    "# data,label = enlever_derniere_ligne_et_colonne_label_frequence(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accélération GYRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = data[\"Foot\"][\"Left\"][\"GYRO\"][\"X\"]\n",
    "# premiere_colonne = a.iloc[:,0]\n",
    "# diff = np.diff(a, prepend=premiere_colonne,axis =  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceleration_gyro (data, fs = 50):\n",
    "    \"\"\"\n",
    "    Calculer l'accélération angulaire à partir des données de vitesse angulaire (gyroscope).\n",
    "\n",
    "    :param data_gyro: DataFrame contenant les vitesses angulaires pour chaque axe (X, Y, Z).\n",
    "    :param delta_t: Intervalle de temps entre les mesures en secondes.\n",
    "    :return: DataFrame contenant l'accélération angulaire pour chaque axe.\n",
    "    \"\"\"\n",
    "    pas_temps = 1/fs\n",
    "    \n",
    "    for sensor, sensor_data in data.items():\n",
    "        if sensor not in [\"metadata\", \"parcours\", \"FOG\"]:\n",
    "            for side, side_data in sensor_data.items():\n",
    "                for measure, measure_data in side_data.items():\n",
    "                    if measure == \"GYRO\":\n",
    "                        for axis, axis_data in measure_data.items():\n",
    "                            # calcul de l'accélération angulaire\n",
    "                            data_acceleration = np.diff(axis_data,axis=1) / pas_temps\n",
    "                            measure_data[axis] = data_acceleration\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temporal_features(data):\n",
    "    \n",
    "    # Initialise un DataFrame vide pour stocker les caractéristiques\n",
    "    df_features = pd.DataFrame()\n",
    "    \n",
    "    # Moyenne\n",
    "    df_features['Mean_Temporal'] = np.mean(data, axis=1)\n",
    "    \n",
    "    # Écart type\n",
    "    df_features['Ecart_Type_Temporal'] = np.std(data, axis=1)\n",
    "    \n",
    "    # Variance\n",
    "    df_features['Variance_Temporal'] = np.var(data, axis=1)\n",
    "    \n",
    "    # Énergie\n",
    "    df_features['Energy_Temporal'] = np.sum(np.square(data), axis=1)\n",
    "    \n",
    "    # Range\n",
    "    df_features['Range'] = np.ptp(data, axis=1)\n",
    "    \n",
    "    # Root mean square\n",
    "    df_features['RMS'] = np.sqrt(np.mean(np.square(data), axis=1))\n",
    "    \n",
    "    # Médiane\n",
    "    df_features['Median_Temporal'] = np.median(data, axis=1)\n",
    "    \n",
    "    # Trimmed mean\n",
    "    df_features['Trimmed_Mean'] = trim_mean(data, 0.1, axis=1)\n",
    "    \n",
    "    # Mean absolute value\n",
    "    df_features['Mean_Absolute_Value'] = np.mean(np.abs(data), axis=1)\n",
    "    \n",
    "    # Median absolute deviation\n",
    "    df_features['Median_Absolute_Deviation'] = median_abs_deviation(data, axis=1, nan_policy='omit')\n",
    "    \n",
    "    # Percentiles\n",
    "    df_features['25th_percentile'] = np.percentile(data, 25, axis=1)\n",
    "    \n",
    "    df_features['75th_percentile'] = np.percentile(data, 75, axis=1)\n",
    "    \n",
    "    # Interquantile range\n",
    "    df_features['Interquartile_range'] = iqr(data, axis=1, rng=(25,75), nan_policy=\"omit\")\n",
    "    \n",
    "    # Skewness\n",
    "    df_features['Skewness_Temporal'] = skew(data, axis=1)\n",
    "    \n",
    "    # Kurtosis\n",
    "    df_features['Kurtosis_Temporal'] = kurtosis(data, axis=1)\n",
    "    \n",
    "    # Incréments moyennes\n",
    "    mean = np.mean(data, axis=1)\n",
    "    df_features['Increments_Mean'] = np.diff(mean, prepend=mean[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # # Coefficients d'autorégression\n",
    "    # fenetres = [np.array(window) for window in data.values]\n",
    "    # max_order = 9\n",
    "    # best_orders = {}\n",
    "    # best_mse = np.inf \n",
    "    # tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "    # for i, fenetre in enumerate(fenetres):\n",
    "    #     best_order = None\n",
    "    #     best_mse = np.inf\n",
    "    \n",
    "    #     for p in range(1, max_order + 1):\n",
    "    #         mse_scores = []\n",
    "        \n",
    "    #         for train_index, test_index in tscv.split(fenetre):\n",
    "    #             train_data, test_data = fenetre[train_index], fenetre[test_index]\n",
    "            \n",
    "    #             model = AutoReg(train_data, lags=p)\n",
    "    #             result = model.fit()\n",
    "    #             predictions = result.predict(start=len(train_data), end=len(train_data) + len(test_data) - 1)\n",
    "    #             mse = mean_squared_error(test_data, predictions)\n",
    "    #             mse_scores.append(mse)\n",
    "        \n",
    "    #         avg_mse = np.mean(mse_scores)\n",
    "\n",
    "    #         if avg_mse < best_mse:\n",
    "    #             best_mse = avg_mse\n",
    "    #             best_order = p\n",
    "    \n",
    "    #     best_orders[i] = best_order\n",
    "\n",
    "    # coefficients_autoreg = []\n",
    "\n",
    "    # for i, fenetre in enumerate(fenetres):\n",
    "    #     modele_ar = AutoReg(fenetre, lags=best_orders[i])\n",
    "    #     resultat = modele_ar.fit()\n",
    "    #     coefficients = resultat.params[best_orders[i]]\n",
    "    #     coefficients_autoreg.append(coefficients) \n",
    "    # df_features['Ar_Coefficients'] = coefficients_autoreg \n",
    "\n",
    "    # Coefficient de variation\n",
    "    df_features['Coefficient_Variation'] = np.std(data, axis=1) / np.mean(data, axis=1)\n",
    "    \n",
    "    # Normalized signal magnitude area\n",
    "    # features['normalized_signal_magnitude_area'] = np.sum(np.abs(np.diff(data, axis=1)), axis=1) / data.shape[1]\n",
    "    \n",
    "    # Mean crossing rate\n",
    "    # features['mean_crossing_rate'] = np.mean(np.diff(data > np.mean(data, axis=1, keepdims=True), axis=1), axis=1)\n",
    "    \n",
    "    # Signal vector magnitude\n",
    "    # features['signal_vector_magnitude'] = np.sqrt(np.sum(np.square(data), axis=1))\n",
    "    \n",
    "    # # Incréments\n",
    "    # # Calculer les différences entre les éléments consécutifs de chaque ligne\n",
    "    # diffs = np.diff(data, axis=1)\n",
    "    # # Insérer une colonne de zéros au début de chaque ligne\n",
    "    # features['increments'] = np.hstack((np.zeros((data.shape[0], 1)), diffs))\n",
    "    # df_features['increments'] = features['increments']\n",
    "    \n",
    "    # Entropie\n",
    "    # features['entropy'] = entropy(data, axis=1)\n",
    "    \n",
    "    # Pic de la transformée de Fourier (FFT)\n",
    "    # f, Pxx = welch(data, axis=1)\n",
    "    # features['fft_peak'] = f[np.argmax(Pxx, axis=1)]\n",
    "    # df_features['fft_peak'] = features['fft_peak']\n",
    "\n",
    "    return df_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On transforme les données en fréquentiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_domaine_frequentiel (data, fs = 50):\n",
    "    # Nombre de points de données par fenêtre\n",
    "    n = data.shape[1]  # ou 100 si c'est connu\n",
    "\n",
    "    # Créer un tableau de fréquences\n",
    "    frequences = fftfreq(n, d=1/fs)\n",
    "    frequences = frequences[:n//2] # obligé de laisser la data en série, pour générer le graphique des spectres de magnitudes\n",
    "    frequencies = fftfreq(n, d=1/fs)\n",
    "    frequencies = frequencies[:n//2]\n",
    "\n",
    "    # Transposer le tableau de fréquences pour le mettre en colonnes\n",
    "    frequencies = frequencies.reshape((1, -1))\n",
    "\n",
    "\n",
    "\n",
    "    # calculer la transformée de Fourier\n",
    "    fft_result = fft(data, axis = 1)\n",
    "    fft_magnitudes = np.abs(fft_result)[:,:n//2] # Garder uniquement les valeurs positives, puisque d'après la symétrie de la FFT, les valeurs négatives sont les mêmes que les valeurs positives\n",
    "\n",
    "\n",
    "\n",
    "    # chemin_fichier_excel_mag = \"C:/Users/antho/Documents/MEMOIRE_M2/magnitude_frequence.csv\"\n",
    "    # chemin_fichier_excel_freq = \"C:/Users/antho/Documents/MEMOIRE_M2/frequence.csv\"\n",
    "\n",
    "    # # Créer un DataFrame pour stocker les magnitudes des fréquences\n",
    "    fft_magnitudes = pd.DataFrame(fft_magnitudes)\n",
    "    frequencies = pd.DataFrame(frequencies)\n",
    "\n",
    "\n",
    "\n",
    "    # # # Exporter le DataFrame en tant que fichier CSV\n",
    "    # fft_magnitudes.to_csv(chemin_fichier_excel_mag, index=False)\n",
    "    # frequencies.to_csv(chemin_fichier_excel_freq, index=False)\n",
    "    return fft_magnitudes, frequencies\n",
    "fft_magnitudes, frequencies = transformation_domaine_frequentiel(data[\"Foot\"][\"Left\"][\"GYRO\"][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcourir le dictionnaire pour trouver et modifier les DataFrames\n",
    "def enlever_derniere_ligne_et_colonne_label(data):\n",
    "    for sensor, sensor_data in data.items():\n",
    "        if sensor not in [\"metadata\", \"parcours\", \"FOG\"]:\n",
    "            for side, side_data in sensor_data.items():\n",
    "                for measure, measure_data in side_data.items():\n",
    "                    for axis, axis_data in measure_data.items():\n",
    "                        if isinstance(axis_data, pd.DataFrame):\n",
    "                        \n",
    "                            # Supprimer la dernière ligne du DataFrame\n",
    "                            data_moins_derniere_ligne_na = axis_data.drop(axis_data.index[-1])\n",
    "                            # print(data_moins_derniere_ligne_na)\n",
    "                            label = data_moins_derniere_ligne_na[\"label\"]\n",
    "                        \n",
    "                            # Vérifier si la colonne 'label' existe avant de la supprimer\n",
    "                            if 'label' in data_moins_derniere_ligne_na.columns:\n",
    "                                data_moins_colonne_label = data_moins_derniere_ligne_na.drop(columns=[\"label\"])\n",
    "                                # Mise à jour du DataFrame dans le dictionnaire\n",
    "                                measure_data[axis] = data_moins_colonne_label\n",
    "    return data, label\n",
    "\n",
    "data, label = enlever_derniere_ligne_et_colonne_label(data)\n",
    "                            \n",
    "                            # Afficher le DataFrame après la modification\n",
    "                        # print(data_moins_colonne_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transofmraiton du tableau clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parcourir le dictionnaire pour trouver et modifier les DataFrames\n",
    "# def enlever_derniere_ligne_et_colonne_label_et_transformation_fft(data):\n",
    "#     for sensor, sensor_data in data.items():\n",
    "#         if sensor not in [\"metadata\", \"parcours\", \"FOG\"]:\n",
    "#             for side, side_data in sensor_data.items():\n",
    "#                 for measure, measure_data in side_data.items():\n",
    "#                     for axis, axis_data in measure_data.items():\n",
    "#                         if isinstance(axis_data, pd.DataFrame):\n",
    "                        \n",
    "#                             # Supprimer la dernière ligne du DataFrame\n",
    "#                             data_moins_derniere_ligne_na = axis_data.drop(axis_data.index[-1])\n",
    "#                             # print(data_moins_derniere_ligne_na)\n",
    "#                             label = data_moins_derniere_ligne_na[\"label\"]\n",
    "                        \n",
    "#                             # Vérifier si la colonne 'label' existe avant de la supprimer\n",
    "#                             if 'label' in data_moins_derniere_ligne_na.columns:\n",
    "#                                 data_moins_colonne_label = data_moins_derniere_ligne_na.drop(columns=[\"label\"])\n",
    "#                                 # Mise à jour du DataFrame dans le dictionnaire\n",
    "#                                 measure_data[axis] = data_moins_colonne_label\n",
    "                                \n",
    "#                                 # Calculer la transformée de Fourier\n",
    "#                             fft_magnitudes, frequencies = transformation_domaine_frequentiel(data_moins_colonne_label)\n",
    "#     return data, label,fft_magnitudes, frequencies\n",
    "\n",
    "# data, label, fft_magnitudes, frequencies = enlever_derniere_ligne_et_colonne_label_et_transformation_fft(data)\n",
    "                            \n",
    "#                             # Afficher le DataFrame après la modification\n",
    "#                         # print(data_moins_colonne_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# J'ai un tableau tout propre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_entropie_spectrale (fft_magnitudes):\n",
    "    # Calculer l'entropie spectrale de puissance pour chaque fenêtre\n",
    "    entropie_spectrale = []\n",
    "\n",
    "    for index, row in fft_magnitudes.iterrows():\n",
    "        # Calculer les proportions pi de la puissance spectrale\n",
    "        puissance_totale = np.sum(row**2)\n",
    "        p_i = (row**2) / puissance_totale\n",
    "    \n",
    "        # Filtrer les valeurs de p_i égales à 0 pour éviter les erreurs de log(0)\n",
    "        p_i = p_i[p_i > 0]\n",
    "\n",
    "        # Calculer l'entropie spectrale pour la fenêtre actuelle\n",
    "        H = -np.sum(p_i * np.log(p_i))\n",
    "        entropie_spectrale.append(H)\n",
    "\n",
    "    # Convertir la liste d'entropie en un tableau numpy pour une manipulation facile\n",
    "    df_entropie_spectrale = pd.DataFrame({'Entropie_Spectrale': entropie_spectrale})\n",
    "    return df_entropie_spectrale\n",
    "\n",
    "# entropie_spectrale = calcul_entropie_spectrale(fft_magnitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_details_harmoniques (fft_magnitudes, frequencies):\n",
    "\n",
    "    # Initialiser les listes pour stocker les résultats\n",
    "    premiere_harmonique_mag = []\n",
    "    deuxieme_harmonique_mag = []\n",
    "    premiere_harmonique_freq = []\n",
    "    deuxieme_harmonique_freq = []\n",
    "    distance_harmonique_frequence = []  # Liste pour stocker la distance entre les harmoniques\n",
    "    distance_harmonique_magnitude = []\n",
    "    centre_densite_spectrale = []\n",
    "    centre_densite_spectrale_puissance = []\n",
    "    rapport_harmonique_frequence = []\n",
    "    rapport_harmonique_magnitude = []\n",
    "    crete_spectrale_puissance_ponderee_gpt = []\n",
    "    crete_spectrale_puissance_ponderee_borzi = []\n",
    "    largeurs_harmoniques = []\n",
    "\n",
    "\n",
    "    # Itérer sur chaque fenêtre\n",
    "    for index, row in fft_magnitudes.iterrows():\n",
    "        magnitudes = row.values\n",
    "        frequences = frequencies.values.flatten() # Assumer que les fréquences sont constantes et identiques pour toutes les fenêtres\n",
    "    \n",
    "        # Trouver les indices des deux plus grandes magnitudes\n",
    "        indices_harmoniques = np.argsort(magnitudes)[-2:]  # Cela nous donne les indices du second puis du premier\n",
    "    \n",
    "        # Assurer que l'indice de la première harmonique est celui de la plus grande magnitude\n",
    "        if magnitudes[indices_harmoniques[0]] > magnitudes[indices_harmoniques[1]]:\n",
    "            premiere_harmonique, deuxieme_harmonique = indices_harmoniques[0], indices_harmoniques[1]\n",
    "        else:\n",
    "            premiere_harmonique, deuxieme_harmonique = indices_harmoniques[1], indices_harmoniques[0]\n",
    "    \n",
    "        # Calculer le centre de densité spectrale (CDS)\n",
    "        cds = np.sum(frequences * magnitudes) / np.sum(magnitudes)\n",
    "    \n",
    "        # Calculer le centre de densité spectrale de puissance\n",
    "        cds_puissance = np.sum(frequences * magnitudes**2) / np.sum(magnitudes**2)\n",
    "    \n",
    "        # Calcul de la crête spectrale de puissance pondérée selon GPT\n",
    "        cs_puissance_ponderee_gpt = np.max(magnitudes**2) / np.sum(magnitudes**2)\n",
    "    \n",
    "        # Calcul de la crête spectrale de puissance pondérée selon Borzi\n",
    "        cs_puissance_ponderee_borzi = ((magnitudes[premiere_harmonique]**2) * frequences[premiere_harmonique])\n",
    "    \n",
    "        # Stocker les résultats\n",
    "        premiere_harmonique_mag.append(magnitudes[premiere_harmonique])\n",
    "        deuxieme_harmonique_mag.append(magnitudes[deuxieme_harmonique])\n",
    "        premiere_harmonique_freq.append(frequences[premiere_harmonique])\n",
    "        deuxieme_harmonique_freq.append(frequences[deuxieme_harmonique])\n",
    "        centre_densite_spectrale.append(cds)\n",
    "        centre_densite_spectrale_puissance.append(cds_puissance)\n",
    "        crete_spectrale_puissance_ponderee_gpt.append(cs_puissance_ponderee_gpt)\n",
    "        crete_spectrale_puissance_ponderee_borzi.append(cs_puissance_ponderee_borzi)\n",
    "    \n",
    "        # Calculer et stocker la distance de fréquence entre les harmoniques\n",
    "        distance_harmonique_frequence.append(abs(frequences[premiere_harmonique] - frequences[deuxieme_harmonique]))\n",
    "    \n",
    "    \n",
    "        # Pour éviter Inf, vérifier si le dénominateur est zéro\n",
    "        if frequences[deuxieme_harmonique] == 0:\n",
    "            rapport_harmonique_frequence.append(0)\n",
    "        else:\n",
    "            rapport_harmonique_frequence.append(frequences[premiere_harmonique] / frequences[deuxieme_harmonique])\n",
    "    \n",
    "    \n",
    "        # Calculer et stocker la distance de magnitude entre les harmoniques\n",
    "        distance_harmonique_magnitude.append(abs(magnitudes[premiere_harmonique] - magnitudes[deuxieme_harmonique]))\n",
    "    \n",
    "        # De même, éviter Inf pour les magnitudes\n",
    "        if magnitudes[deuxieme_harmonique] == 0:\n",
    "            rapport_harmonique_magnitude.append(0)\n",
    "        else:\n",
    "            rapport_harmonique_magnitude.append(magnitudes[premiere_harmonique] / magnitudes[deuxieme_harmonique])\n",
    "        \n",
    "        \n",
    "           \n",
    "        # Calculer la largeur des harmoniques\n",
    "            # Calculer la magnitude de la première harmonique\n",
    "        premiere_harmonique_magnitude = magnitudes[premiere_harmonique]\n",
    "    \n",
    "        # Utiliser la bonne méthode pour trouver les indices gauche et droite\n",
    "        # Trouver l'indice de gauche\n",
    "        gauche = np.where(magnitudes[:premiere_harmonique] < premiere_harmonique_magnitude * 0.5)[0]\n",
    "        if len(gauche) > 0:\n",
    "            indice_gauche = gauche[-1] + 1  # Prendre le dernier indice sous le seuil et ajouter 1\n",
    "        else:\n",
    "            indice_gauche = 0  # S'il n'y a pas de valeur sous le seuil, prendre le début du signal\n",
    "    \n",
    "        # Trouver l'indice de droite\n",
    "        droite = np.where(magnitudes[premiere_harmonique+1:] < premiere_harmonique_magnitude * 0.5)[0]\n",
    "        if len(droite) > 0:\n",
    "            indice_droite = droite[0] + premiere_harmonique + 1  # Prendre le premier indice sous le seuil après le pic\n",
    "        else:\n",
    "            indice_droite = len(magnitudes) - 1  # S'il n'y a pas de valeur sous le seuil, prendre la fin du signal\n",
    "    \n",
    "        # Calculer la largeur en Hz\n",
    "        largeur_hz = frequences[indice_droite] - frequences[indice_gauche]\n",
    "        largeurs_harmoniques.append(largeur_hz)\n",
    "\n",
    "    # Créer un DataFrame pour les résultats\n",
    "    df_resultats = pd.DataFrame({\n",
    "        'Premiere_Harmonique_Magnitude': premiere_harmonique_mag,\n",
    "        'Deuxieme_Harmonique_Magnitude': deuxieme_harmonique_mag,\n",
    "        'Premiere_Harmonique_Frequence': premiere_harmonique_freq,\n",
    "        'Deuxieme_Harmonique_Frequence': deuxieme_harmonique_freq,\n",
    "        'Distance_Harmonique_Frequence': distance_harmonique_frequence,\n",
    "        'Distance_Harmonique_Amplitude':  distance_harmonique_magnitude,\n",
    "        'Rapport_Harmonique_Frequence': rapport_harmonique_frequence,\n",
    "        'Rapport_Harmonique_Amplitude':  rapport_harmonique_magnitude,\n",
    "        'Centre_Densite_Spectrale': centre_densite_spectrale,\n",
    "        'Centre_Densite_Spectrale_Puissance': centre_densite_spectrale_puissance,\n",
    "        'Crete_Spectrale_Puissance_Ponderee_GPT': crete_spectrale_puissance_ponderee_gpt,\n",
    "        'Crete_Spectrale_Puissance_Ponderee_Borzi': crete_spectrale_puissance_ponderee_borzi,\n",
    "        'Largeur_Harmonique': largeurs_harmoniques\n",
    "        })\n",
    "    \n",
    "    return df_resultats\n",
    "    # return premiere_harmonique_mag,deuxieme_harmonique_mag,premiere_harmonique_freq,deuxieme_harmonique_freq, distance_harmonique_frequence,distance_harmonique_magnitude,rapport_harmonique_frequence,rapport_harmonique_magnitude, centre_densite_spectrale,centre_densite_spectrale_puissance, crete_spectrale_puissance_ponderee_gpt, crete_spectrale_puissance_ponderee_borzi, largeurs_harmoniques\n",
    "\n",
    "# # Afficher les premières lignes du DataFrame résultant pour vérification\n",
    "# print(df_resultats.head())\n",
    "# df_resultats = calcul_details_harmoniques(fft_magnitudes, frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecart_type_borne (fft_magnitudes, frequencies):\n",
    "    # Définissons les bandes de fréquences spécifiées\n",
    "    bandes_frequence = {\n",
    "        'ecart_type': (0, 50),\n",
    "        'ecart_type_0.04_0.68_Hz': (0.04, 0.68),\n",
    "        'ecart_type_0.68_3_Hz': (0.68, 3),\n",
    "        'ecart_type_3_8_Hz': (3, 8),\n",
    "        'ecart_type_8_20_Hz': (8, 20),\n",
    "        'ecart_type_0.1_8_Hz': (0.1, 8)\n",
    "    }\n",
    "\n",
    "    # Extrayons les fréquences depuis le fichier frequence.csv pour l'associer à chaque colonne de magnitude_frequence.csv\n",
    "    frequences = frequencies.values.flatten()\n",
    "\n",
    "    # Créons un DataFrame pour stocker les écarts types calculés pour chaque bande de fréquence et pour chaque ligne (fenêtre)\n",
    "    ecarts_types = pd.DataFrame()\n",
    "\n",
    "    # Pour chaque bande de fréquence, filtrons les données et calculons l'écart type\n",
    "    for nom_bande, (freq_min, freq_max) in bandes_frequence.items():\n",
    "    \n",
    "        # Identifions les colonnes correspondant à la bande de fréquence\n",
    "        colonnes_bande = (frequences >= freq_min) & (frequences <= freq_max)\n",
    "    \n",
    "        # Filtrons les magnitudes pour cette bande de fréquence\n",
    "        magnitudes_bande = fft_magnitudes.loc[:, colonnes_bande]\n",
    "    \n",
    "        # Calculons l'écart type pour cette bande de fréquence et ajoutons les résultats au DataFrame\n",
    "        ecarts_types[nom_bande] = magnitudes_bande.std(axis=1)\n",
    "        \n",
    "    return ecarts_types\n",
    "\n",
    "# # # Affichons les premières lignes des résultats pour vérifier\n",
    "# ecarts_type = ecart_type_borne(fft_magnitudes, frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculer_freeze_index(fft_magnitudes, frequencies):\n",
    "    \"\"\"\n",
    "    Calcule le Freeze Index pour chaque fenêtre de données.\n",
    "    \n",
    "    :param magnitudes: Un DataFrame ou un numpy array des magnitudes du spectre de puissance pour chaque fenêtre.\n",
    "    :param frequences: Un numpy array des fréquences correspondant aux colonnes de magnitudes.\n",
    "    :return: Un numpy array contenant le Freeze Index pour chaque fenêtre.\n",
    "    \"\"\"\n",
    "    magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "    frequences = frequencies.values.flatten()\n",
    "    \n",
    "    # Définissons une fonction interne pour calculer l'aire sous le spectre de puissance\n",
    "    def calculer_aire_sous_spectre(frequences, magnitudes, freq_min, freq_max):\n",
    "        indices_bande = (frequences >= freq_min) & (frequences <= freq_max)\n",
    "        magnitudes_bande = magnitudes[:, indices_bande]\n",
    "        aire_sous_spectre = np.trapz(magnitudes_bande, x=frequences[indices_bande], axis=1)\n",
    "        return aire_sous_spectre\n",
    "\n",
    "    # Bandes de fréquences pour le Freeze Index\n",
    "    bande_freeze = (3, 8)  # Bande \"freeze\"\n",
    "    bande_locomotrice = (0.5, 3)  # Bande \"locomotrice\"\n",
    "\n",
    "    # Calcul de l'aire sous le spectre pour chaque bande\n",
    "    aire_freeze = calculer_aire_sous_spectre(frequences, magnitudes, *bande_freeze)\n",
    "    aire_locomotrice = calculer_aire_sous_spectre(frequences, magnitudes, *bande_locomotrice)\n",
    "\n",
    "    # Calcul du Freeze Index\n",
    "    freeze_index = (aire_freeze ** 2) / (aire_locomotrice ** 2)\n",
    "    freeze_index_df = pd.DataFrame({'Freeze_Index': freeze_index})\n",
    "\n",
    "    return freeze_index_df\n",
    "\n",
    "# Exemple d'utilisation de la fonction `calculer_freeze_index`\n",
    "# Assurez-vous que `magnitude_frequence_df` et `frequences` sont définis et chargés correctement\n",
    "# magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "# frequences = frequencies.values.flatten()\n",
    "\n",
    "# # Calculons le Freeze Index\n",
    "# freeze_index_resultats = calculer_freeze_index(fft_magnitudes, frequencies)\n",
    "\n",
    "# # Créons un DataFrame pour afficher les Freeze Index calculés\n",
    "# freeze_index_df = pd.DataFrame({'Freeze Index': freeze_index_resultats})\n",
    "\n",
    "# # Affichage des premiers résultats\n",
    "# print(freeze_index_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fréquence de faible Puissance pour une bande fréquence entre 0 et 2 Hz\n",
    "def ratio_faible_puissance_entre_0_2Hz (fft_magnitudes,frequencies):\n",
    "    # Assurez-vous que `magnitude_frequence_df` et `frequences` sont définis et chargés correctement\n",
    "    magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "    frequences = frequencies.values.flatten()\n",
    "\n",
    "    ratios = []  # Pour stocker le ratio de chaque fenêtre\n",
    "    psd = np.abs(magnitudes)**2  # Calcul de la densité spectrale de puissance\n",
    "    puissance_totale = np.sum(psd, axis=1)  # Calcul de la puissance totale du signal pour chaque fenêtre\n",
    "    \n",
    "    # Filtrer pour obtenir la puissance dans la bande 0-2 Hz\n",
    "    bande_indices = (frequences >= 0) & (frequences <= 2)\n",
    "    psd_band= psd[:, bande_indices]\n",
    "    puissance_bande = np.sum(psd_band, axis = 1)\n",
    "        \n",
    "    ratios = puissance_bande / puissance_totale\n",
    "    ratios_df = pd.DataFrame({'Ratio_Faible_Puissance_0_2Hz': ratios})\n",
    "    return ratios_df\n",
    "\n",
    "# ratio_faible_puissance_entre = ratio_faible_puissance_entre_0_2Hz(fft_magnitudes, frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_band_freq (fft_magnitudes,frequencies):\n",
    "    magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "    frequences = frequencies.values.flatten()\n",
    "\n",
    "\n",
    "    # Définissons les bandes de fréquences spécifiées\n",
    "    bandes_frequence = {\n",
    "        'Skewness': (0, 50),\n",
    "        'Skewness_0.04_0.68_Hz': (0.04, 0.68),\n",
    "        'Skewness_0.68_3_Hz': (0.68, 3),\n",
    "        'Skewness_3_8_Hz': (3, 8),\n",
    "        'Skewness_8_20_Hz': (8, 20),\n",
    "        'Skewness_0.1_8_Hz': (0.1, 8)\n",
    "    }\n",
    "\n",
    "    # Créons un DataFrame pour stocker les écarts types calculés pour chaque bande de fréquence et pour chaque ligne (fenêtre)\n",
    "    skwenesss = pd.DataFrame()\n",
    "\n",
    "    # Pour chaque bande de fréquence, filtrons les données et calculons l'écart type\n",
    "    for nom_bande, (freq_min, freq_max) in bandes_frequence.items():\n",
    "    \n",
    "        # Identifions les colonnes correspondant à la bande de fréquence\n",
    "        colonnes_bande = (frequences >= freq_min) & (frequences <= freq_max)\n",
    "    \n",
    "        # Filtrons les magnitudes pour cette bande de fréquence\n",
    "        magnitudes_bande = fft_magnitudes.loc[:, colonnes_bande]\n",
    "    \n",
    "        # Calculons l'écart type pour cette bande de fréquence et ajoutons les résultats au DataFrame\n",
    "        skwenesss[nom_bande] = magnitudes_bande.skew(axis=1)\n",
    "\n",
    "    # Affichons les premières lignes des résultats pour vérifier\n",
    "    # skwenesss.head()\n",
    "    return skwenesss\n",
    "\n",
    "# skewnesss = skewness_band_freq(fft_magnitudes, frequencies)\n",
    "# print(skewnesss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosis_band_freq (fft_magnitudes, frequencies) :\n",
    "    magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "    frequences = frequencies.values.flatten()\n",
    "    # Définissons les bandes de fréquences spécifiées\n",
    "    bandes_frequence = {\n",
    "        'Kurtosis': (0, 50),\n",
    "        'Kurtosis_0.04_0.68_Hz': (0.04, 0.68),\n",
    "        'Kurtosis_0.68_3_Hz': (0.68, 3),\n",
    "        'Kurtosis_3_8_Hz': (3, 8),\n",
    "        'Kurtosis_8_20_Hz': (8, 20),\n",
    "        'Kurtosis_0.1_8_Hz': (0.1, 8)\n",
    "    }\n",
    "\n",
    "    # Créons un DataFrame pour stocker les écarts types calculés pour chaque bande de fréquence et pour chaque ligne (fenêtre)\n",
    "    kurtosiss = pd.DataFrame()\n",
    "\n",
    "    # Pour chaque bande de fréquence, filtrons les données et calculons l'écart type\n",
    "    for nom_bande, (freq_min, freq_max) in bandes_frequence.items():\n",
    "    \n",
    "        # Identifions les colonnes correspondant à la bande de fréquence\n",
    "        colonnes_bande = (frequences >= freq_min) & (frequences <= freq_max)\n",
    "    \n",
    "        # Filtrons les magnitudes pour cette bande de fréquence\n",
    "        magnitudes_bande = fft_magnitudes.loc[:, colonnes_bande]\n",
    "    \n",
    "        # Calculons l'écart type pour cette bande de fréquence et ajoutons les résultats au DataFrame\n",
    "        kurtosiss[nom_bande] = magnitudes_bande.kurtosis(axis=1)\n",
    "\n",
    "    # Affichons les premières lignes des résultats pour vérifier\n",
    "    kurtosiss.head()\n",
    "    \n",
    "    return kurtosiss\n",
    "\n",
    "# kurtosisss = kurtosis_band_freq(fft_magnitudes,frequencies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_locomotion_band_power (fft_magnitudes,frequencies):\n",
    "# Locomotion band power\n",
    "    magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "    frequences = frequencies.values.flatten()\n",
    "    # Filtrer pour obtenir la puissance dans la bande de locomotion (0.5-3 Hz)\n",
    "    bande_locomotion_power_list = []\n",
    "    psd = np.abs(magnitudes)**2 \n",
    "    bande_locomotion = (frequences >= 0.5) & (frequences <= 3)\n",
    "    psd_bande_locomotion = psd[:, bande_locomotion]\n",
    "    puissance_bande_locomotion = np.sum(psd_bande_locomotion, axis=1)\n",
    "\n",
    "    for window in puissance_bande_locomotion:\n",
    "        bande_locomotion_power = window / 50\n",
    "        bande_locomotion_power_list.append(bande_locomotion_power)\n",
    "    \n",
    "    df_bande_locomotion_power = pd.DataFrame({'Locomotion_Band_Power': bande_locomotion_power_list})\n",
    "    return df_bande_locomotion_power\n",
    "\n",
    "# df_bande_locomotion_power = calcul_locomotion_band_power (fft_magnitudes,frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_freeze_band_power (fft_magnitudes,frequencies):\n",
    "    magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "    frequences = frequencies.values.flatten()\n",
    "    # Filtrer pour obtenir la puissance dans la bande de locomotion (3-8 Hz)\n",
    "    bande_freeze_power_list = []\n",
    "    psd = np.abs(magnitudes)**2 \n",
    "\n",
    "\n",
    "    bande_freeze = (frequences >= 3) & (frequences <= 8)\n",
    "    psd_bande_freeze = psd[:, bande_freeze]\n",
    "    puissance_bande_freeze = np.sum(psd_bande_freeze, axis=1)\n",
    "\n",
    "    for window in puissance_bande_freeze:\n",
    "        bande_freeze_power = window / 50\n",
    "        bande_freeze_power_list.append(bande_freeze_power)\n",
    "    \n",
    "    df_bande_freeze_power = pd.DataFrame({'Freeze_Band_Power': bande_freeze_power_list})\n",
    "    return df_bande_freeze_power\n",
    "\n",
    "# df_bande_freeze_power = calcul_freeze_band_power (fft_magnitudes,frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_band_power(fft_magnitudes,frequencies):\n",
    "# Locomotion band power\n",
    "    magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "    frequences = frequencies.values.flatten()\n",
    "    bande_power_list = []\n",
    "    psd = np.abs(magnitudes)**2 \n",
    "\n",
    "    # Filtrer pour obtenir la puissance dans la bande de locomotion et de freezing (0.5-8 Hz)\n",
    "    bande_power = (frequences >= 0.5) & (frequences <= 8)\n",
    "    psd_bande_power = psd[:, bande_power]\n",
    "    puissance_bande_power= np.sum(psd_bande_power, axis=1)\n",
    "\n",
    "    for window in puissance_bande_power:\n",
    "        bande_power = window / 50\n",
    "        bande_power_list.append(bande_power)\n",
    "        \n",
    "    df_bande_power = pd.DataFrame({'Band_Power': bande_power_list})\n",
    "    return df_bande_power\n",
    "\n",
    "# df_bande_power = calcul_band_power(fft_magnitudes,frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.72566467e-01 9.46192111e-02 1.07801133e-01 ... 2.72972956e-02\n",
      "  2.74153162e-02 2.75214529e-02]\n",
      " [8.95439816e-02 1.37756693e-01 2.56330650e-01 ... 1.29205351e-02\n",
      "  6.95074148e-03 3.53161617e-03]\n",
      " [2.32534969e-02 2.02083559e-01 2.79244124e-01 ... 9.71912585e-03\n",
      "  4.30092330e-03 1.58857905e-03]\n",
      " ...\n",
      " [3.94110445e-01 3.78997418e-01 3.66308776e+00 ... 2.31804154e-01\n",
      "  1.99940405e-01 2.06730770e-01]\n",
      " [5.85250917e-01 3.79651419e-01 3.64725374e+00 ... 3.61726803e-02\n",
      "  3.20103006e-02 1.71799826e-02]\n",
      " [2.03156645e+00 1.15160239e+00 4.81574169e+00 ... 4.65950890e-02\n",
      "  7.35252990e-02 5.73201830e-02]]\n",
      "             \n",
      "           0         1         2         3         4         5         6   \\\n",
      "0    0.172566  0.094619  0.107801  0.113411  0.116325  0.098645  0.097024   \n",
      "1    0.089544  0.137757  0.256331  0.330293  0.364966  0.345725  0.306609   \n",
      "2    0.023253  0.202084  0.279244  0.281971  0.338149  0.370547  0.333817   \n",
      "3    0.118937  0.233605  0.284691  0.316140  0.292930  0.424411  0.275582   \n",
      "4    0.089745  0.214441  0.316011  0.197559  0.424372  0.449078  0.272385   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "136  0.105021  0.460950  3.432219  0.737824  4.650005  0.966629  2.820071   \n",
      "137  0.061698  0.647579  3.679546  0.847993  4.630551  0.825451  2.789612   \n",
      "138  0.394110  0.378997  3.663088  1.951846  4.853311  2.692679  2.030653   \n",
      "139  0.585251  0.379651  3.647254  1.670091  4.522266  3.139253  2.422953   \n",
      "140  2.031566  1.151602  4.815742  0.356595  4.707611  2.629746  1.200588   \n",
      "\n",
      "           7         8         9   ...        40        41        42  \\\n",
      "0    0.100601  0.094299  0.081544  ...  0.028801  0.027963  0.027706   \n",
      "1    0.253444  0.213858  0.191839  ...  0.111104  0.092027  0.073335   \n",
      "2    0.246096  0.198382  0.196369  ...  0.114415  0.095379  0.075719   \n",
      "3    0.303851  0.164471  0.214980  ...  0.094551  0.117408  0.053065   \n",
      "4    0.550771  0.229486  0.500588  ...  0.225727  0.216372  0.079339   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "136  0.812943  1.119835  0.641026  ...  0.137563  0.205747  0.041712   \n",
      "137  0.876363  1.282466  0.319721  ...  0.113224  0.248951  0.080426   \n",
      "138  2.267418  0.532243  1.105902  ...  0.201175  0.147109  0.133630   \n",
      "139  2.271522  0.565013  0.927053  ...  0.610085  0.289071  0.408946   \n",
      "140  3.403137  0.930972  2.078202  ...  0.581824  0.360882  0.363331   \n",
      "\n",
      "           43        44        45        46        47        48        49  \n",
      "0    0.027604  0.027916  0.027525  0.027538  0.027297  0.027415  0.027521  \n",
      "1    0.055969  0.042274  0.030177  0.020623  0.012921  0.006951  0.003532  \n",
      "2    0.056222  0.041144  0.028750  0.018427  0.009719  0.004301  0.001589  \n",
      "3    0.078117  0.023336  0.047957  0.016363  0.028605  0.020271  0.022397  \n",
      "4    0.151207  0.031696  0.072376  0.028135  0.019303  0.010746  0.001448  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "136  0.190332  0.063736  0.124328  0.016034  0.049249  0.016583  0.016462  \n",
      "137  0.199581  0.096061  0.194990  0.104428  0.055014  0.086786  0.081491  \n",
      "138  0.372420  0.215393  0.301560  0.202193  0.231804  0.199940  0.206731  \n",
      "139  0.221281  0.107162  0.075384  0.054783  0.036173  0.032010  0.017180  \n",
      "140  0.239338  0.105300  0.106072  0.095404  0.046595  0.073525  0.057320  \n",
      "\n",
      "[141 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "def calcul_energie (fft_magnitudes, frequencies):\n",
    "    magnitudes = fft_magnitudes.values  # Convertissons le DataFrame en numpy array si ce n'est pas déjà le cas\n",
    "    \n",
    "    # Calcul de l'énergie pour chaque signal (chaque ligne)\n",
    "    energy = np.sum(np.abs(magnitudes)**2 / len(magnitudes), axis=1)\n",
    "    \n",
    "    # Créer un DataFrame pour stocker les résultats\n",
    "    df_energie = pd.DataFrame({'Energie_Frequentielle': energy})\n",
    "        \n",
    "    return df_energie\n",
    "\n",
    "df_energie = calcul_energie(fft_magnitudes, frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction finale de toutes les caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_caracteristiques_final(data):\n",
    "    data_collect = []\n",
    "\n",
    "    for sensor, sensor_data in data.items():\n",
    "        if sensor not in [\"metadata\", \"parcours\", \"FOG\"]:\n",
    "            for side, side_data in sensor_data.items():\n",
    "                for measure, measure_data in side_data.items():\n",
    "                    for axis, axis_data in measure_data.items():\n",
    "                        if isinstance(axis_data, pd.DataFrame):\n",
    "                            # Application des fonctions pour calculer les caractéristiques temporelles\n",
    "                            df_temporal = extract_temporal_features(axis_data)\n",
    "                            \n",
    "                            # Application des fonctions pour calculer les caractéristiques fréquentielles\n",
    "                            fft_magnitude, frequencies = transformation_domaine_frequentiel(axis_data, fs=50)\n",
    "                            entropie_spectrale = calcul_entropie_spectrale(fft_magnitude)\n",
    "                            details_harmoniques = calcul_details_harmoniques(fft_magnitude, frequencies)\n",
    "                            ecart_types = ecart_type_borne(fft_magnitude, frequencies)\n",
    "                            freeze_index = calculer_freeze_index(fft_magnitude, frequencies)\n",
    "                            ratio_faible_puissance = ratio_faible_puissance_entre_0_2Hz(fft_magnitude, frequencies)\n",
    "                            skewness = skewness_band_freq(fft_magnitude, frequencies)\n",
    "                            kurtosis = kurtosis_band_freq(fft_magnitude, frequencies)\n",
    "                            locomotion_band_power = calcul_locomotion_band_power(fft_magnitude, frequencies)\n",
    "                            freeze_band_power = calcul_freeze_band_power(fft_magnitude, frequencies)\n",
    "                            band_power = calcul_band_power(fft_magnitude, frequencies)\n",
    "                            energie = calcul_energie(fft_magnitude, frequencies)\n",
    "                            \n",
    "\n",
    "                            # Fusionner toutes les caractéristiques dans un seul DataFrame pour simplification\n",
    "                            caract_features = pd.concat([df_temporal,   \n",
    "                                                         entropie_spectrale,\n",
    "                                                         details_harmoniques, \n",
    "                                                         ecart_types,\n",
    "                                                         freeze_index,\n",
    "                                                         ratio_faible_puissance,\n",
    "                                                         skewness,\n",
    "                                                         kurtosis,\n",
    "                                                         locomotion_band_power,\n",
    "                                                         freeze_band_power,\n",
    "                                                         band_power,\n",
    "                                                         energie], axis=1)\n",
    "\n",
    "                            # Renommer les colonnes ici\n",
    "                            caract_features.rename(columns={feature_name: f\"{sensor}_{side}_{measure}_{axis}_{feature_name}\" for feature_name in caract_features.columns}, inplace=True)\n",
    "                            \n",
    "                            data_collect.append(caract_features)\n",
    "\n",
    "    # Concaténer toutes les données collectées en alignant les colonnes\n",
    "    df_final = pd.concat(data_collect, axis=1)\n",
    "    return df_final\n",
    "\n",
    "# Supposons que `data` est déjà défini et structuré correctement\n",
    "df_final = dataframe_caracteristiques_final(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_fichier_csv_data_final = \"C:/Users/antho/Documents/MEMOIRE_M2/data_final.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # # Exporter le DataFrame en tant que fichier CSV\n",
    "df_final.to_csv(chemin_fichier_csv_data_final, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataframe = pd.DataFrame(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([df_final,label_dataframe],axis = 1)\n",
    "combined_df = data_concat[['label'] + [col for col in data_concat.columns if col != 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
